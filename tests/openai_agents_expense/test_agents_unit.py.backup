"""Unit tests for individual OpenAI Agents in the expense processing workflow"""

import json
import sys
from decimal import Decimal
from datetime import date
from unittest.mock import AsyncMock, patch, MagicMock

import pytest

# Skip if Python < 3.11 to avoid OpenAI type errors
pytestmark = pytest.mark.skipif(
    sys.version_info < (3, 11), 
    reason="OpenAI support has type errors on Python < 3.11"
)

# Test data fixtures
@pytest.fixture
def sample_expense():
    """Sample expense report for testing"""
    from openai_agents_expense.models import ExpenseReport
    
    return ExpenseReport(
        expense_id="EXP-001",
        amount=Decimal("45.00"),
        description="Office supplies - pens, paper, folders",
        vendor="Staples Inc",
        date=date.today(),
        department="Engineering",
        employee_id="EMP-123",
        receipt_provided=True,
        submission_date=date.today(),
        client_name=None,
        business_justification=None,
        is_international_travel=False
    )


@pytest.fixture
def sample_vendor_validation():
    """Sample vendor validation for testing"""
    from openai_agents_expense.models import VendorValidation
    
    return VendorValidation(
        vendor_name="Staples Inc",
        is_legitimate=True,
        confidence_score=0.98,
        web_search_summary="Staples Inc. is a major office supply chain with website at staples.com"
    )


@pytest.fixture
def sample_expense_category(sample_vendor_validation):
    """Sample expense category for testing"""
    from openai_agents_expense.models import ExpenseCategory
    
    return ExpenseCategory(
        category="Office Supplies",
        confidence=0.95,
        reasoning="Clear office supplies from legitimate vendor",
        vendor_validation=sample_vendor_validation
    )


class TestCategoryAgent:
    """Unit tests for CategoryAgent workflow function"""
    
    @pytest.mark.asyncio
    async def test_categorize_office_supplies(self, sample_expense):
        """Test categorize_expense workflow function correctly categorizes office supplies"""
        from openai_agents_expense.ai_agents.category_agent import categorize_expense
        from openai_agents_expense.models import ExpenseCategory, VendorValidation
        
        # Mock the Runner.run to return expected agent response
        expected_result = ExpenseCategory(
            category="Office Supplies",
            confidence=0.95,
            reasoning="Office supplies from Staples, confirmed legitimate vendor",
            vendor_validation=VendorValidation(
                vendor_name="Staples Inc",
                is_legitimate=True,
                confidence_score=0.98,
                web_search_summary="Major office supply retailer with verified website"
            )
        )
        
        # Mock the OpenAI Agent Runner
        mock_agent_result = type('MockResult', (), {
            'final_output': '''
            {
                "category": "Office Supplies",
                "confidence": 0.95,
                "reasoning": "Office supplies from Staples, confirmed legitimate vendor",
                "vendor_validation": {
                    "vendor_name": "Staples Inc",
                    "is_legitimate": true,
                    "confidence_score": 0.98,
                    "web_search_summary": "Major office supply retailer with verified website"
                }
            }
            '''
        })()
        
        with patch('openai_agents_expense.ai_agents.category_agent.Runner.run', return_value=mock_agent_result):
            result = await categorize_expense(sample_expense)
            
            assert result.category == "Office Supplies"
            assert result.confidence >= 0.9
            assert result.vendor_validation.is_legitimate is True

    @pytest.mark.asyncio
    async def test_categorize_suspicious_vendor(self, sample_expense):
        """Test categorize_expense handles suspicious vendor"""
        from openai_agents_expense.ai_agents.category_agent import categorize_expense
        from openai_agents_expense.models import ExpenseCategory, VendorValidation
        
        # Modify expense to have suspicious vendor
        sample_expense.vendor = "Joe's Totally Legit Restaurant LLC"
        sample_expense.description = "Business meal"
        sample_expense.amount = Decimal("200.00")
        
        # Mock the OpenAI Agent Runner response for suspicious vendor
        mock_agent_result = type('MockResult', (), {
            'final_output': '''
            {
                "category": "Meals & Entertainment",
                "confidence": 0.75,
                "reasoning": "Restaurant expense but vendor not found in web search",
                "vendor_validation": {
                    "vendor_name": "Joe's Totally Legit Restaurant LLC",
                    "is_legitimate": false,
                    "confidence_score": 0.1,
                    "web_search_summary": "No results found for this vendor name"
                }
            }
            '''
        })()
        
        with patch('openai_agents_expense.ai_agents.category_agent.Runner.run', return_value=mock_agent_result):
            result = await categorize_expense(sample_expense)
            
            assert result.category == "Meals & Entertainment"
            assert result.vendor_validation.is_legitimate is False
            assert result.confidence < 0.8  # Lower confidence due to suspicious vendor


class TestPolicyEvaluationAgent:
    """Unit tests for PolicyEvaluationAgent workflow function"""
    
    @pytest.mark.asyncio
    async def test_evaluate_compliant_expense(self, sample_expense, sample_expense_category):
        """Test evaluate_policy_compliance approves compliant expense"""
        from openai_agents_expense.ai_agents.policy_evaluation_agent import evaluate_policy_compliance
        from openai_agents_expense.models import PolicyEvaluation
        
        # Mock the OpenAI Agent Runner response for compliant expense
        mock_agent_result = type('MockResult', (), {
            'final_output': '''
            {
                "compliant": true,
                "violations": [],
                "reasoning": "Office supplies under $75, no violations detected",
                "requires_human_review": false,
                "mandatory_human_review": false,
                "policy_explanation": "Office supplies under $75 are automatically approved",
                "confidence": 0.92
            }
            '''
        })()
        
        with patch('openai_agents_expense.ai_agents.policy_evaluation_agent.Runner.run', return_value=mock_agent_result):
            result = await evaluate_policy_compliance(sample_expense, sample_expense_category)
            
            assert result.compliant is True
            assert len(result.violations) == 0
            assert result.requires_human_review is False
            assert result.mandatory_human_review is False

    @pytest.mark.asyncio
    async def test_evaluate_international_travel_mandatory_escalation(self, sample_expense, sample_expense_category):
        """Test PolicyEvaluationAgent flags mandatory escalation for international travel"""
        from openai_agents_expense.ai_agents.policy_evaluation_agent import PolicyEvaluationAgent
        from openai_agents_expense.models import PolicyEvaluation, PolicyViolation
        
        # Modify expense for international travel
        sample_expense.is_international_travel = True
        sample_expense.amount = Decimal("400.00")
        sample_expense.description = "Flight to London"
        sample_expense.vendor = "British Airways"
        sample_expense_category.category = "Travel & Transportation"
        
        agent = PolicyEvaluationAgent()
        expected_result = PolicyEvaluation(
            compliant=False,
            violations=[
                PolicyViolation(
                    rule_name="International Travel",
                    violation_type="mandatory_review",
                    severity="requires_review",
                    details="All international travel requires human approval"
                )
            ],
            reasoning="International travel requires mandatory review",
            requires_human_review=True,
            mandatory_human_review=True,
            policy_explanation="All international travel must be approved by manager",
            confidence=0.98
        )
        
        with patch.object(agent, 'evaluate', return_value=expected_result):
            result = await agent.evaluate(sample_expense, sample_expense_category)
            
            assert result.compliant is False
            assert result.mandatory_human_review is True
            assert len(result.violations) == 1
            assert result.violations[0].rule_name == "International Travel"

    @pytest.mark.asyncio
    async def test_evaluate_over_flight_limit(self, sample_expense, sample_expense_category):
        """Test PolicyEvaluationAgent flags expenses over flight limit"""
        from openai_agents_expense.ai_agents.policy_evaluation_agent import PolicyEvaluationAgent
        from openai_agents_expense.models import PolicyEvaluation, PolicyViolation
        
        # Modify expense for expensive flight
        sample_expense.amount = Decimal("750.00")
        sample_expense.description = "Flight to conference"
        sample_expense.vendor = "Delta Airlines"
        sample_expense_category.category = "Travel & Transportation"
        
        agent = PolicyEvaluationAgent()
        expected_result = PolicyEvaluation(
            compliant=False,
            violations=[
                PolicyViolation(
                    rule_name="Flight Limit",
                    violation_type="mandatory_review",
                    severity="requires_review",
                    details="Flights over $500 require human approval",
                    threshold_amount=Decimal("500.00")
                )
            ],
            reasoning="Flight expense exceeds $500 limit",
            requires_human_review=True,
            mandatory_human_review=True,
            policy_explanation="Flights over $500 require manager approval",
            confidence=0.95
        )
        
        with patch.object(agent, 'evaluate', return_value=expected_result):
            result = await agent.evaluate(sample_expense, sample_expense_category)
            
            assert result.compliant is False
            assert result.mandatory_human_review is True
            assert result.violations[0].threshold_amount == Decimal("500.00")


class TestFraudAgent:
    """Unit tests for FraudAgent"""
    
    @pytest.mark.asyncio
    async def test_assess_low_risk_expense(self, sample_expense, sample_expense_category):
        """Test FraudAgent assesses legitimate expense as low risk"""
        from openai_agents_expense.ai_agents.fraud_agent import FraudAgent
        from openai_agents_expense.models import FraudAssessment
        
        agent = FraudAgent()
        expected_result = FraudAssessment(
            overall_risk="low",
            flags=[],
            reasoning="Low risk - legitimate vendor and reasonable amount",
            requires_human_review=False,
            confidence=0.88,
            vendor_risk_indicators=[]
        )
        
        with patch.object(agent, 'assess', return_value=expected_result) as mock_assess:
            result = await agent.assess(sample_expense, sample_expense_category)
            
            assert result.overall_risk == "low"
            assert len(result.flags) == 0
            assert result.requires_human_review is False
            mock_assess.assert_called_once_with(sample_expense, sample_expense_category)

    @pytest.mark.asyncio
    async def test_assess_high_risk_suspicious_vendor(self, sample_expense, sample_expense_category):
        """Test FraudAgent flags suspicious non-existent vendor"""
        from openai_agents_expense.ai_agents.fraud_agent import FraudAgent
        from openai_agents_expense.models import FraudAssessment, FraudFlag
        
        # Modify for suspicious vendor
        sample_expense.vendor = "Joe's Totally Legit Restaurant LLC"
        sample_expense.description = "Business meal"
        sample_expense.amount = Decimal("200.00")
        sample_expense_category.category = "Meals & Entertainment"
        sample_expense_category.vendor_validation.is_legitimate = False
        sample_expense_category.vendor_validation.confidence_score = 0.1
        
        agent = FraudAgent()
        expected_result = FraudAssessment(
            overall_risk="high",
            flags=[
                FraudFlag(
                    flag_type="suspicious_vendor",
                    risk_level="high",
                    details="Vendor not found in web search results"
                )
            ],
            reasoning="High risk due to non-existent vendor",
            requires_human_review=True,
            confidence=0.92,
            vendor_risk_indicators=["vendor_not_found", "suspicious_name"]
        )
        
        with patch.object(agent, 'assess', return_value=expected_result):
            result = await agent.assess(sample_expense, sample_expense_category)
            
            assert result.overall_risk == "high"
            assert len(result.flags) == 1
            assert result.flags[0].flag_type == "suspicious_vendor"
            assert result.requires_human_review is True

    @pytest.mark.asyncio
    async def test_assess_round_number_bias(self, sample_expense, sample_expense_category):
        """Test FraudAgent flags suspiciously round amounts"""
        from openai_agents_expense.ai_agents.fraud_agent import FraudAgent
        from openai_agents_expense.models import FraudAssessment, FraudFlag
        
        # Set exact round number
        sample_expense.amount = Decimal("100.00")
        sample_expense.description = "Office supplies"
        
        agent = FraudAgent()
        expected_result = FraudAssessment(
            overall_risk="medium",
            flags=[
                FraudFlag(
                    flag_type="round_number_bias",
                    risk_level="medium",
                    details="Suspiciously round amount"
                )
            ],
            reasoning="Medium risk due to round number amount",
            requires_human_review=False,
            confidence=0.75,
            vendor_risk_indicators=["round_amount"]
        )
        
        with patch.object(agent, 'assess', return_value=expected_result):
            result = await agent.assess(sample_expense, sample_expense_category)
            
            assert result.overall_risk == "medium"
            assert any(flag.flag_type == "round_number_bias" for flag in result.flags)


class TestDecisionOrchestrationAgent:
    """Unit tests for DecisionOrchestrationAgent"""
    
    @pytest.mark.asyncio
    async def test_decide_auto_approve(self, sample_expense):
        """Test DecisionOrchestrationAgent auto-approves low-risk compliant expense"""
        from openai_agents_expense.ai_agents.decision_orchestration_agent import DecisionOrchestrationAgent
        from openai_agents_expense.models import PolicyEvaluation, FraudAssessment, FinalDecision
        
        policy_eval = PolicyEvaluation(
            compliant=True,
            violations=[],
            reasoning="Compliant expense",
            requires_human_review=False,
            mandatory_human_review=False,
            policy_explanation="Under $75, no violations",
            confidence=0.92
        )
        
        fraud_assessment = FraudAssessment(
            overall_risk="low",
            flags=[],
            reasoning="Low risk",
            requires_human_review=False,
            confidence=0.88,
            vendor_risk_indicators=[]
        )
        
        agent = DecisionOrchestrationAgent()
        expected_result = FinalDecision(
            decision="approved",
            internal_reasoning="Clear approval case",
            external_reasoning="Expense approved - legitimate and compliant",
            escalation_reason=None,
            is_mandatory_escalation=False,
            confidence=0.91
        )
        
        with patch.object(agent, 'decide', return_value=expected_result) as mock_decide:
            result = await agent.decide(sample_expense, policy_eval, fraud_assessment)
            
            assert result.decision == "approved"
            assert result.is_mandatory_escalation is False
            assert result.confidence > 0.8
            mock_decide.assert_called_once_with(sample_expense, policy_eval, fraud_assessment)

    @pytest.mark.asyncio
    async def test_decide_mandatory_escalation_overrides_ai(self, sample_expense):
        """Test DecisionOrchestrationAgent escalates when mandatory rules require it"""
        from openai_agents_expense.ai_agents.decision_orchestration_agent import DecisionOrchestrationAgent
        from openai_agents_expense.models import PolicyEvaluation, FraudAssessment, FinalDecision, PolicyViolation
        
        policy_eval = PolicyEvaluation(
            compliant=False,
            violations=[
                PolicyViolation(
                    rule_name="International Travel",
                    violation_type="mandatory_review",
                    severity="requires_review",
                    details="International travel requires approval"
                )
            ],
            reasoning="Mandatory escalation required",
            requires_human_review=True,
            mandatory_human_review=True,
            policy_explanation="International travel policy",
            confidence=0.98
        )
        
        # Even with low fraud risk, should still escalate due to mandatory rule
        fraud_assessment = FraudAssessment(
            overall_risk="low",
            flags=[],
            reasoning="Low fraud risk",
            requires_human_review=False,
            confidence=0.85,
            vendor_risk_indicators=[]
        )
        
        agent = DecisionOrchestrationAgent()
        expected_result = FinalDecision(
            decision="requires_human_review",
            internal_reasoning="Mandatory escalation overrides AI assessment",
            external_reasoning="Requires manager approval per international travel policy",
            escalation_reason="Mandatory policy requirement",
            is_mandatory_escalation=True,
            confidence=0.95
        )
        
        with patch.object(agent, 'decide', return_value=expected_result):
            result = await agent.decide(sample_expense, policy_eval, fraud_assessment)
            
            assert result.decision == "requires_human_review"
            assert result.is_mandatory_escalation is True
            assert result.escalation_reason == "Mandatory policy requirement"

    @pytest.mark.asyncio
    async def test_decide_low_confidence_escalation(self, sample_expense):
        """Test DecisionOrchestrationAgent escalates on low confidence"""
        from openai_agents_expense.ai_agents.decision_orchestration_agent import DecisionOrchestrationAgent
        from openai_agents_expense.models import PolicyEvaluation, FraudAssessment, FinalDecision
        
        # Low confidence policy evaluation
        policy_eval = PolicyEvaluation(
            compliant=True,
            violations=[],
            reasoning="Uncertain categorization",
            requires_human_review=True,
            mandatory_human_review=False,
            policy_explanation="Unclear policy application",
            confidence=0.65  # Below threshold
        )
        
        # Low confidence fraud assessment
        fraud_assessment = FraudAssessment(
            overall_risk="medium",
            flags=[],
            reasoning="Uncertain risk assessment",
            requires_human_review=True,
            confidence=0.60,  # Below threshold
            vendor_risk_indicators=[]
        )
        
        agent = DecisionOrchestrationAgent()
        expected_result = FinalDecision(
            decision="requires_human_review",
            internal_reasoning="Low confidence scores trigger escalation",
            external_reasoning="Requires review due to uncertain assessment",
            escalation_reason="Low confidence assessment",
            is_mandatory_escalation=False,
            confidence=0.62
        )
        
        with patch.object(agent, 'decide', return_value=expected_result):
            result = await agent.decide(sample_expense, policy_eval, fraud_assessment)
            
            assert result.decision == "requires_human_review"
            assert result.is_mandatory_escalation is False
            assert "confidence" in result.escalation_reason.lower()


class TestResponseAgent:
    """Unit tests for ResponseAgent"""
    
    @pytest.mark.asyncio
    async def test_generate_approval_response(self, sample_expense, sample_expense_category):
        """Test ResponseAgent generates appropriate approval response"""
        from openai_agents_expense.ai_agents.response_agent import ResponseAgent
        from openai_agents_expense.models import FinalDecision, PolicyEvaluation, ExpenseResponse
        
        decision = FinalDecision(
            decision="approved",
            internal_reasoning="Clear approval",
            external_reasoning="Legitimate expense, policy compliant",
            escalation_reason=None,
            is_mandatory_escalation=False,
            confidence=0.91
        )
        
        policy_eval = PolicyEvaluation(
            compliant=True,
            violations=[],
            reasoning="Compliant",
            requires_human_review=False,
            mandatory_human_review=False,
            policy_explanation="Standard approval",
            confidence=0.92
        )
        
        agent = ResponseAgent()
        expected_result = ExpenseResponse(
            message="Your expense has been approved! Your $45.00 office supplies purchase will be processed.",
            decision_summary="Approved - Standard office supplies expense",
            policy_explanation="Office supplies under $75 auto-approved",
            categorization_summary="Office Supplies from legitimate vendor"
        )
        
        with patch.object(agent, 'generate_response', return_value=expected_result) as mock_generate:
            result = await agent.generate_response(sample_expense, decision, policy_eval, sample_expense_category)
            
            assert "approved" in result.message.lower()
            assert result.decision_summary.startswith("Approved")
            assert "Office Supplies" in result.categorization_summary
            mock_generate.assert_called_once_with(sample_expense, decision, policy_eval, sample_expense_category)

    @pytest.mark.asyncio
    async def test_generate_escalation_response(self, sample_expense, sample_expense_category):
        """Test ResponseAgent generates appropriate escalation response"""
        from openai_agents_expense.ai_agents.response_agent import ResponseAgent
        from openai_agents_expense.models import FinalDecision, PolicyEvaluation, ExpenseResponse
        
        decision = FinalDecision(
            decision="requires_human_review",
            internal_reasoning="Mandatory escalation due to policy",
            external_reasoning="Requires manager approval per company policy",
            escalation_reason="Mandatory policy requirement",
            is_mandatory_escalation=True,
            confidence=0.95
        )
        
        policy_eval = PolicyEvaluation(
            compliant=False,
            violations=[],
            reasoning="Mandatory review required",
            requires_human_review=True,
            mandatory_human_review=True,
            policy_explanation="International travel policy",
            confidence=0.98
        )
        
        agent = ResponseAgent()
        expected_result = ExpenseResponse(
            message="Your expense has been forwarded for manager review per company policy. You will be notified once reviewed.",
            decision_summary="Requires Review - Mandatory policy escalation",
            policy_explanation="International travel requires manager approval",
            categorization_summary="Travel expense requiring additional approval"
        )
        
        with patch.object(agent, 'generate_response', return_value=expected_result):
            result = await agent.generate_response(sample_expense, decision, policy_eval, sample_expense_category)
            
            assert "review" in result.message.lower()
            assert "Requires Review" in result.decision_summary
            assert "manager" in result.message.lower() or "review" in result.message.lower()

    @pytest.mark.asyncio
    async def test_generate_rejection_with_instructions(self, sample_expense, sample_expense_category):
        """Test ResponseAgent generates rejection with correction instructions"""
        from openai_agents_expense.ai_agents.response_agent import ResponseAgent
        from openai_agents_expense.models import FinalDecision, PolicyEvaluation, ExpenseResponse
        
        decision = FinalDecision(
            decision="rejected_with_instructions",
            internal_reasoning="Missing required information",
            external_reasoning="Missing client name for entertainment expense",
            escalation_reason=None,
            is_mandatory_escalation=False,
            confidence=0.85
        )
        
        policy_eval = PolicyEvaluation(
            compliant=False,
            violations=[],
            reasoning="Missing client information",
            requires_human_review=False,
            mandatory_human_review=False,
            policy_explanation="Entertainment expenses require client name",
            confidence=0.88
        )
        
        agent = ResponseAgent()
        expected_result = ExpenseResponse(
            message="Your expense needs additional information. Please resubmit with the client name for this entertainment expense.",
            decision_summary="Rejected - Missing required client information",
            policy_explanation="Entertainment expenses require client name and business justification",
            categorization_summary="Entertainment expense requiring additional details"
        )
        
        with patch.object(agent, 'generate_response', return_value=expected_result):
            result = await agent.generate_response(sample_expense, decision, policy_eval, sample_expense_category)
            
            assert "resubmit" in result.message.lower() or "additional" in result.message.lower()
            assert "Rejected" in result.decision_summary
            assert "client" in result.message.lower() or "information" in result.message.lower() 